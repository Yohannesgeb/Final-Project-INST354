# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O0x-AO9exjoWDc54h8Rc3VHOcN0adzZa

# **Introduction**

Group: David Zhang, Jessica Vo, Samson George, Yohannes Gebremariam

Dataset: https://www.kaggle.com/datasets/ahmettezcantekin/beginner-datasets

Our data set is Blood Transfusion dataset from Kaggle and it has a little less than 1000 rows. This data consists of recency, frequency, monetary, time, and class. Recency is the time (months) since the last time a person intended to give blood. Frequency is the number of times a person intended to give blood in the past. Monetary is the amount of blood (cc) given in the past. Time is the amount of months since the first time a person intended to give blood. Class is donated (1) or not donated (0). 

Our target variable is class, whether a person donated or has not donated blood. Our predictor variables are recency, frequency, monetary, and time. These predicttor variables lets us know about people that intended to give blood. We did not have any null values. 

Some questions that we are interested in:

*   Are people who donated in 2007 more likely to frequently donate in the coming months?
*   Are people who has been donating blood in the recent months new donors, or are they established donors, donating for over a year?
*   Are people more likely to donate blood when they have donated recently or when they waited a while?

## Importing packages (libraries)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn import preprocessing
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

bloodty_df = pd.read_csv("blood.csv")

bloodty_df.head()

from google.colab import drive
drive.mount('/content/drive')

"""## Features and Target"""

x = bloodty_df.iloc[:,0:-1]
y = bloodty_df.Class
x.head()

"""## Split the data into train and test"""

x_train, x_test, y_train, y_test=train_test_split(x,y,test_size = 0.25, random_state = 120)

"""## Instantiate, preprocess, train and predict (test)"""

# Initial logistic regression
LogReg = LogisticRegression()

scaler = preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

LogReg.fit(x_train, y_train)

y_pred = LogReg.predict(x_test)

print('Classes', LogReg.classes_)
print('Intercept', LogReg.intercept_)
print('Coefficients', LogReg.coef_)

"""# **Classification Report**

"""

print('Accuracy', LogReg.score(x_test, y_test))
print(classification_report(y_test, LogReg.predict(x_test)))

"""### **F1-Score**"""

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))

"""**F1-Score Analysis**



*   *F1-score*: The model’s ability to both capture those who donated blood and be accurate with the cases it does capture is 0.16, which means that it doesn’t capture it very well.  
*   *Precision*: This means that we predicted that 62.5% of the people would donate blood and they actually did.
*   *Recall*: This means that 9.09% of the people who actually donated blood were predicted to have donated blood.

# **Confusion Matrix**

Plot the Confusion Matrix and explain the output
"""

conf_mat = confusion_matrix(y_test, y_pred)
conf_mat

""" ***Explain the output***

*   Of the 187 cases, 135 of those who were predicted to donate blood actually donated blood. 

*  Of the 187 cases, 0 of those who were predicted to donate blood didn’t actually donate blood

*   
Of the 187 cases, 0 of those who were predicted to not donate blood actually donated blood.

*   Of the 187 cases, 55 of those who were predicted too not donate blood didn’t actually donate blood.

"""

categories = [0,1] 
fig, ax = plt.subplots()
plt.xticks([0,1], categories)
plt.yticks([0,1], categories)

# create heatmap
sns.heatmap(bloodty_df.corr())

"""# ***Splitting the Time in months since the first time a person intended to give blood.***
"""

category = ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)']

X = bloodty_df.iloc[:,:-1]
Y = bloodty_df.iloc[:, -1]

x_train, x_test, y_train, y_test=train_test_split(x,y,test_size = 0.25, random_state = 0)

LogReg = LogisticRegression()

scaler = preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

LogReg.fit(x_train, y_train)

y_pred = LogReg.predict(x_test)

print('Classes', LogReg.classes_)
print('Intercept', LogReg.intercept_)
print('Coefficients', LogReg.coef_)

"""# **Confusion Matrix** Plotting the Confusion Matrix """

conf_mat = confusion_matrix(y_test, y_pred)
conf_mat

categories = [0,1] 
fig, ax = plt.subplots()
plt.xticks([0,1], categories)
plt.yticks([0,1], categories)

"""**Fairness in AI Decision Making**

To be defined, precision of a model describes how many detected items are truly relevant, recall being the measure of how many relevant elements were detected, and false positives being the measures of accuracy for a test.

AI decision making can potentially make wrong perceptions when an individual inputs wrong information intentionally or unintentionally, and can have detrimental impact on patients and blood recipients.

# Process Explanation

In this code, the 'x' and 'y' variables represent the input data from the blood donor dataset (blood.csv). The 'x' variable contains the data's features (or attributes), such as the time since the last donation. The 'y' variable includes the labels for the data, which in this case, are the categories into wheater a person donated blood or not. 
The 'train_test_split' function is used to split the input data into training and testing sets. The 'test_size' and 'random_state' parameters control the proportions of the data allocated to the training and testing sets, and the random seed is used to shuffle the data before splitting it.

After splitting the data, we used a logistic regression model to Instantiate, preprocess, train and predict tests using the 'LogReg.fit' method. This model is used to make predictions on the testing set using the 'LogReg.predict' process, and the predictions are stored in the 'y_pred' variable.

The model's performance is evaluated using a variety of metrics, including accuracy, precision, recall, and F1-Score. These metrics are calculated using the accuracy_score, precision_score, recall_score, and classification_report functions from sci-kit-learn.

The code also creates a confusion matrix to visualize the model's performance. This is done using the confusion_matrix function from sci-kit-learn, and the resulting matrix is plotted using the seaborn library.

Finally, the data is split into different categories based on the time since the person last donated blood. This is done using the pd.cut function from the panda's library, which divides the data into bins based on the specified boundaries. A new column is added to the data containing the categories, and a new logistic regression model is trained and evaluated on this data.

This code uses logistic regression to classify blood donors into different categories based on the time since they last donated blood and evaluates the model's performance using a variety of the previously mentioned metrics.
"""